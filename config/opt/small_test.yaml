training:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  num_train_epochs: 1
  dataloader_num_workers: 16
  fp16: true
  optim: "adamw_torch"
  learning_rate: 5.0e-5
  logging_steps: 100
  save_strategy: "steps"
  save_steps: 4000
  save_total_limit: 1
  deepspeed: configs/deepspeed/ds_config_zero1.json
  output_dir: ./output/
  report_to: "wandb"

pretrain_name:
vision_pretrain_name: 
model:
  binary_action_dims: 
  analogue_action_dims:

preprocessor:
  frame_emb_len: 1


dataset:
  dataset_index_path:
  action_dir:
  video_dir:
  transcripts_dir:

wandb:
  project: "AlexOPT"
  name: "small_test"